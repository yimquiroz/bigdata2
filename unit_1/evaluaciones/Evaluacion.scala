//Authors: Alonso Alvarez, Yim Quiroz
//Instituto Tecnologico de Tijuana
//Materia: Datos Masivos
//Evaluacion Unidad 1

/*The first step is to import the library to create an entry point 
to sqlspark and create a session in spark*/
import org.apache.spark.sql.SparkSession 
val spark = SparkSession.builder().getOrCreate()

//2-. The next step is to load the Netflix CSV file, with the dataframe df and spark infer the data types
val df = spark.read.option("header","true").option("inferSchema","true").csv("Netflix_2011_2016.csv")

//3-.In the following instruction it is in charge of showing us the columns with our df followed by the word column
df.columns

//4-.It shows us the scheme that are the characteristics of the columns
df.printSchema() 

//5-. It takes care of printing the first 5 columns
df.head(5) 

//6-.The describes ()returns the basic metadata information of the df
df.describe().show() 

/*7.- Create a new dataframe whit a new column named "HV_Ratio" who is the relation of the price of "high" columns
and "volume" of action negotiated by day */
val df_hv = df.withColumn("HV Ratio",df("High")/df("Volume"))
df_hv.columns

//8.- What day had the highest peak in the “Close” column?
df.orderBy($"High".desc).show(1)

 //9.- Who is the mean of the column "close" ?

 //Answer: This column is the average between the columns "open", "high" and "low"
df.select(mean("Close")).show()

// 10. What is the maximum and minimum of the “Volume” column?
df.select(max("Volume")).show()
df.select(min("Volume")).show()

//11.
// Sintaxis Scala/Spark
import spark.implicits._

//a. How many days the column "close" was lowe tha $600?
df.filter($"Close"<600).count()

//b. Who percentage of the time was the column "High" higher than $500?
(df.filter($"High" > 500).count() 

// c. Find the Pearson correlation of the colums "high" and "volume"
df.select(corr("High","Volume")).show()

//d. Who was the maximun in the column "high" by year?
val yeardataframe = df.withColumn("Year",year(df("Date")))
val yearmaxs = yeardataframe.select($"Year",$"High").groupBy("Year").max()
val res = yearmaxs.select($"Year",$"max(High)")
res.orderBy("Year").show()

//e. Find the average of the column "close" for each month of the year
val monthdataframe = df.withColumn("Month",month(df("Date")))
val monthavgs = monthdataframe.select($"Month",$"Close").groupBy("Month").mean()
monthavgs.select($"Month",$"avg(Close)").orderBy("Month").show()